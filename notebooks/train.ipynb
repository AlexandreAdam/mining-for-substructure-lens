{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train likelihood ratio estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:29 matplotlib.pyplot    DEBUG   Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append('../')\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from units import *\n",
    "from inference.inference import Estimator\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)-5.5s %(name)-20.20s %(levelname)-7.7s %(message)s',\n",
    "    datefmt='%H:%M',\n",
    "    level=logging.DEBUG\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = Estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:29 inference.inference  INFO    Starting training\n",
      "11:29 inference.inference  INFO      Method:                 alices\n",
      "11:29 inference.inference  INFO      Training data:          x at ../data/x.npy\n",
      "11:29 inference.inference  INFO                              theta0 at ../data/theta.npy\n",
      "11:29 inference.inference  INFO                              y at ../data/y.npy\n",
      "11:29 inference.inference  INFO                              r_xz at ../data/r_xz.npy\n",
      "11:29 inference.inference  INFO                              t_xz (theta0) at ../data/t_xz.npy\n",
      "11:29 inference.inference  INFO      Method:                 alices\n",
      "11:29 inference.inference  INFO      Convolutional layers:   2\n",
      "11:29 inference.inference  INFO      Dense layers:           1\n",
      "11:29 inference.inference  INFO      Feature maps:           10\n",
      "11:29 inference.inference  INFO      Convolutional filter:   5\n",
      "11:29 inference.inference  INFO      Pooling filter:         2\n",
      "11:29 inference.inference  INFO      Activation function:    relu\n",
      "11:29 inference.inference  INFO      alpha:                  1.0\n",
      "11:29 inference.inference  INFO      Batch size:             128\n",
      "11:29 inference.inference  INFO      Trainer:                amsgrad\n",
      "11:29 inference.inference  INFO      Epochs:                 50\n",
      "11:29 inference.inference  INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "11:29 inference.inference  INFO      Validation split:       None\n",
      "11:29 inference.inference  INFO      Early stopping:         True\n",
      "11:29 inference.inference  INFO      Rescale pixel values:   True\n",
      "11:29 inference.inference  INFO      Shuffle labels          False\n",
      "11:29 inference.inference  INFO      Regularization:         None\n",
      "11:29 inference.inference  INFO      Samples:                all\n",
      "11:29 inference.inference  INFO    Loading training data\n",
      "11:29 inference.utils      WARNING Warning: file ../data/r_xz.npy has some large numbers, rangin from 0.013733457238061316 to 1.8621928741962473e+93\n",
      "11:29 inference.utils      WARNING Warning: file ../data/t_xz.npy has some large numbers, rangin from -2.8700346613330827e+56 to 4.1485354280690545e+56\n",
      "11:29 inference.inference  INFO    Found 1000 samples with 2 parameters and resolution 52 x 52\n",
      "11:29 inference.inference  INFO    Rescaling pixel values by factor 1 / 835.0867456209847\n",
      "11:29 inference.inference  DEBUG   Creating model\n",
      "11:29 inference.inference  INFO    Training model\n",
      "11:29 inference.trainer    DEBUG   Training on CPU with single precision\n",
      "11:29 inference.trainer    DEBUG   Model score will be calculated\n",
      "11:29 inference.trainer    DEBUG   Preparing data\n",
      "11:29 inference.trainer    DEBUG   Preparing optimizer amsgrad\n",
      "11:29 inference.trainer    DEBUG   Beginning main training loop\n",
      "11:29 inference.trainer    DEBUG   theta0: tensor([[ 0.0000, -1.9808],\n",
      "        [ 0.0000, -1.9287],\n",
      "        [ 0.0000, -1.8929],\n",
      "        [ 0.0000, -1.8953],\n",
      "        [ 0.0000, -1.8043],\n",
      "        [ 0.0000, -1.9749],\n",
      "        [ 0.0000, -1.8839],\n",
      "        [ 0.0000, -1.9622],\n",
      "        [ 0.0000, -1.8418],\n",
      "        [ 0.0000, -1.9008],\n",
      "        [ 0.0000, -1.9321],\n",
      "        [ 0.0000, -1.8679],\n",
      "        [ 0.0000, -1.9267],\n",
      "        [ 0.0000, -1.9225],\n",
      "        [ 0.0000, -1.9568],\n",
      "        [ 0.0000, -1.8026],\n",
      "        [ 0.0000, -1.9133],\n",
      "        [ 0.0000, -1.8934],\n",
      "        [ 0.0000, -1.9013],\n",
      "        [ 0.0000, -1.8408],\n",
      "        [ 0.0000, -1.9432],\n",
      "        [ 0.0000, -1.9464],\n",
      "        [ 0.0000, -1.8515],\n",
      "        [ 0.0000, -1.8506],\n",
      "        [ 0.0000, -1.9481],\n",
      "        [ 0.0000, -1.9784],\n",
      "        [ 0.0000, -1.8927],\n",
      "        [ 0.0000, -1.9853],\n",
      "        [ 0.0000, -1.9129],\n",
      "        [ 0.0000, -1.9096],\n",
      "        [ 0.0000, -1.9187],\n",
      "        [ 0.0000, -1.8716],\n",
      "        [ 0.0000, -1.8593],\n",
      "        [ 0.0000, -1.9331],\n",
      "        [ 0.0000, -1.8957],\n",
      "        [ 0.0000, -1.9388],\n",
      "        [ 0.0000, -1.8631],\n",
      "        [ 0.0000, -2.0079],\n",
      "        [ 0.0000, -1.9532],\n",
      "        [ 0.0000, -1.8388],\n",
      "        [ 0.0000, -1.9288],\n",
      "        [ 0.0000, -1.8987],\n",
      "        [ 0.0000, -1.9519],\n",
      "        [ 0.0000, -1.9021],\n",
      "        [ 0.0000, -1.9232],\n",
      "        [ 0.0000, -1.8416],\n",
      "        [ 0.0000, -1.9463],\n",
      "        [ 0.0000, -1.8626],\n",
      "        [ 0.0000, -1.9254],\n",
      "        [ 0.0000, -1.9974],\n",
      "        [ 0.0000, -1.9537],\n",
      "        [ 0.0000, -1.8770],\n",
      "        [ 0.0000, -1.8664],\n",
      "        [ 0.0000, -1.8328],\n",
      "        [ 0.0000, -1.8195],\n",
      "        [ 0.0000, -1.8574],\n",
      "        [ 0.0000, -1.8520],\n",
      "        [ 0.0000, -1.7397],\n",
      "        [ 0.0000, -1.8379],\n",
      "        [ 0.0000, -1.8160],\n",
      "        [ 0.0000, -1.8722],\n",
      "        [ 0.0000, -1.7721],\n",
      "        [ 0.0000, -1.8691],\n",
      "        [ 0.0000, -1.8716],\n",
      "        [ 0.0000, -1.9331],\n",
      "        [ 0.0000, -1.9448],\n",
      "        [ 0.0000, -1.8537],\n",
      "        [ 0.0000, -1.8925],\n",
      "        [ 0.0000, -1.9492],\n",
      "        [ 0.0000, -1.8717],\n",
      "        [ 0.0000, -1.8405],\n",
      "        [ 0.0000, -1.8982],\n",
      "        [ 0.0000, -1.9024],\n",
      "        [ 0.0000, -1.9059],\n",
      "        [ 0.0000, -1.9086],\n",
      "        [ 0.0000, -1.9171],\n",
      "        [ 0.0000, -1.8546],\n",
      "        [ 0.0000, -1.8593],\n",
      "        [ 0.0000, -1.8299],\n",
      "        [ 0.0000, -1.9306],\n",
      "        [ 0.0000, -1.8806],\n",
      "        [ 0.0000, -1.8986],\n",
      "        [ 0.0000, -1.8378],\n",
      "        [ 0.0000, -1.9805],\n",
      "        [ 0.0000, -1.8060],\n",
      "        [ 0.0000, -1.8705],\n",
      "        [ 0.0000, -1.8616],\n",
      "        [ 0.0000, -1.9417],\n",
      "        [ 0.0000, -1.8850],\n",
      "        [ 0.0000, -1.8852],\n",
      "        [ 0.0000, -1.8976],\n",
      "        [ 0.0000, -1.9980],\n",
      "        [ 0.0000, -1.9232],\n",
      "        [ 0.0000, -1.9626],\n",
      "        [ 0.0000, -1.8794],\n",
      "        [ 0.0000, -1.9322],\n",
      "        [ 0.0000, -1.8258],\n",
      "        [ 0.0000, -1.9373],\n",
      "        [ 0.0000, -1.9079],\n",
      "        [ 0.0000, -1.9378],\n",
      "        [ 0.0000, -1.9666],\n",
      "        [ 0.0000, -1.8395],\n",
      "        [ 0.0000, -1.9453],\n",
      "        [ 0.0000, -1.8853],\n",
      "        [ 0.0000, -1.8552],\n",
      "        [ 0.0000, -1.9161],\n",
      "        [ 0.0000, -1.8990],\n",
      "        [ 0.0000, -1.9080],\n",
      "        [ 0.0000, -1.9175],\n",
      "        [ 0.0000, -1.9509],\n",
      "        [ 0.0000, -1.8353],\n",
      "        [ 0.0000, -1.8844],\n",
      "        [ 0.0000, -1.8748],\n",
      "        [ 0.0000, -1.8879],\n",
      "        [ 0.0000, -1.8793],\n",
      "        [ 0.0000, -1.9575],\n",
      "        [ 0.0000, -1.9674],\n",
      "        [ 0.0000, -1.8230],\n",
      "        [ 0.0000, -1.9245],\n",
      "        [ 0.0000, -1.8602],\n",
      "        [ 0.0000, -1.9843],\n",
      "        [ 0.0000, -1.8694],\n",
      "        [ 0.0000, -1.9370],\n",
      "        [ 0.0000, -1.9694],\n",
      "        [ 0.0000, -1.9409],\n",
      "        [ 0.0000, -1.8682],\n",
      "        [ 0.0000, -1.9596],\n",
      "        [ 0.0000, -1.8335]], grad_fn=<CopyBackwards>)\n",
      "11:29 inference.trainer    DEBUG   x: tensor([[[0.1688, 0.2036, 0.1808,  ..., 0.1700, 0.1844, 0.2048],\n",
      "         [0.1868, 0.1880, 0.2012,  ..., 0.1964, 0.2108, 0.1784],\n",
      "         [0.2191, 0.1952, 0.2072,  ..., 0.1676, 0.2084, 0.1844],\n",
      "         ...,\n",
      "         [0.1916, 0.1988, 0.1904,  ..., 0.1988, 0.1760, 0.1832],\n",
      "         [0.2132, 0.2179, 0.1940,  ..., 0.2036, 0.2096, 0.1856],\n",
      "         [0.1844, 0.1808, 0.1832,  ..., 0.1820, 0.2000, 0.2155]],\n",
      "\n",
      "        [[0.1760, 0.1940, 0.2132,  ..., 0.1988, 0.1676, 0.1952],\n",
      "         [0.1880, 0.1820, 0.1748,  ..., 0.1724, 0.1928, 0.1988],\n",
      "         [0.1880, 0.2096, 0.1748,  ..., 0.1664, 0.1964, 0.1940],\n",
      "         ...,\n",
      "         [0.1976, 0.2036, 0.1856,  ..., 0.1976, 0.1880, 0.2120],\n",
      "         [0.1964, 0.2143, 0.1820,  ..., 0.1952, 0.1940, 0.1964],\n",
      "         [0.1952, 0.1772, 0.2012,  ..., 0.1856, 0.1712, 0.1820]],\n",
      "\n",
      "        [[0.1976, 0.1664, 0.1844,  ..., 0.1712, 0.1844, 0.1772],\n",
      "         [0.1808, 0.1832, 0.1832,  ..., 0.1988, 0.2227, 0.1617],\n",
      "         [0.1676, 0.1904, 0.2024,  ..., 0.1772, 0.1796, 0.1832],\n",
      "         ...,\n",
      "         [0.1916, 0.1760, 0.2012,  ..., 0.1820, 0.1712, 0.1820],\n",
      "         [0.2072, 0.1928, 0.1736,  ..., 0.1868, 0.1700, 0.2000],\n",
      "         [0.1880, 0.1581, 0.1940,  ..., 0.1916, 0.1904, 0.1976]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1820, 0.1928, 0.1832,  ..., 0.2084, 0.2024, 0.1844],\n",
      "         [0.1629, 0.2024, 0.1629,  ..., 0.1784, 0.1772, 0.1916],\n",
      "         [0.1760, 0.1844, 0.1928,  ..., 0.2371, 0.1892, 0.1784],\n",
      "         ...,\n",
      "         [0.1856, 0.1868, 0.1605,  ..., 0.1820, 0.1904, 0.1832],\n",
      "         [0.1928, 0.1856, 0.1916,  ..., 0.1868, 0.1988, 0.1688],\n",
      "         [0.1796, 0.1736, 0.2155,  ..., 0.1772, 0.1629, 0.1916]],\n",
      "\n",
      "        [[0.2012, 0.2096, 0.1760,  ..., 0.1856, 0.1832, 0.1880],\n",
      "         [0.2132, 0.2012, 0.1844,  ..., 0.1988, 0.2084, 0.1892],\n",
      "         [0.1653, 0.2072, 0.1676,  ..., 0.1784, 0.1808, 0.2024],\n",
      "         ...,\n",
      "         [0.1880, 0.1772, 0.1964,  ..., 0.2060, 0.1712, 0.1940],\n",
      "         [0.1772, 0.1820, 0.2012,  ..., 0.2048, 0.2036, 0.1796],\n",
      "         [0.2024, 0.1940, 0.1760,  ..., 0.2048, 0.1904, 0.2000]],\n",
      "\n",
      "        [[0.1928, 0.1653, 0.2012,  ..., 0.1808, 0.1904, 0.1664],\n",
      "         [0.1856, 0.2072, 0.1868,  ..., 0.1712, 0.1832, 0.1952],\n",
      "         [0.2215, 0.1712, 0.1928,  ..., 0.1700, 0.2108, 0.1916],\n",
      "         ...,\n",
      "         [0.1916, 0.1892, 0.1892,  ..., 0.1724, 0.1928, 0.1593],\n",
      "         [0.2120, 0.1808, 0.1940,  ..., 0.2227, 0.1736, 0.1964],\n",
      "         [0.1904, 0.1808, 0.1724,  ..., 0.1844, 0.1916, 0.1916]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:29 inference.trainer    DEBUG   y: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "11:29 inference.trainer    DEBUG   r_xz: tensor([[1.7757e+01],\n",
      "        [2.2808e+00],\n",
      "        [7.1833e+00],\n",
      "        [7.1169e+00],\n",
      "        [4.0511e+03],\n",
      "        [4.6863e+01],\n",
      "        [7.9261e+00],\n",
      "        [1.9122e+00],\n",
      "        [3.8198e+01],\n",
      "        [1.1442e+01],\n",
      "        [5.9255e+00],\n",
      "        [1.6685e+01],\n",
      "        [8.0949e+00],\n",
      "        [3.2738e+00],\n",
      "        [9.0205e+00],\n",
      "        [2.4091e+02],\n",
      "        [4.6261e+00],\n",
      "        [7.3743e+00],\n",
      "        [1.0539e+01],\n",
      "        [2.4122e+00],\n",
      "        [4.5805e+00],\n",
      "        [8.6377e-01],\n",
      "        [1.5329e+01],\n",
      "        [1.4267e+01],\n",
      "        [1.3644e+01],\n",
      "        [8.4020e+00],\n",
      "        [2.7728e+00],\n",
      "        [1.4699e+01],\n",
      "        [8.8014e-01],\n",
      "        [1.0855e+01],\n",
      "        [6.3289e+00],\n",
      "        [1.1609e+01],\n",
      "        [1.4950e+01],\n",
      "        [8.9008e+00],\n",
      "        [6.0903e+00],\n",
      "        [5.2446e+00],\n",
      "        [2.1734e+01],\n",
      "        [2.5755e+01],\n",
      "        [1.3460e+01],\n",
      "        [2.9651e+01],\n",
      "        [2.5949e+00],\n",
      "        [1.0946e+01],\n",
      "        [9.0165e+00],\n",
      "        [5.7344e-01],\n",
      "        [9.5056e-01],\n",
      "        [3.9490e+00],\n",
      "        [3.9502e+00],\n",
      "        [1.9564e+01],\n",
      "        [7.7857e+00],\n",
      "        [1.5729e+01],\n",
      "        [9.8546e+00],\n",
      "        [2.1043e+01],\n",
      "        [1.1604e+01],\n",
      "        [7.0485e+01],\n",
      "        [3.0662e+01],\n",
      "        [2.0072e+01],\n",
      "        [2.2687e+01],\n",
      "        [       inf],\n",
      "        [5.4431e+01],\n",
      "        [1.1566e+02],\n",
      "        [1.1190e+01],\n",
      "        [2.5969e+09],\n",
      "        [1.0726e+01],\n",
      "        [1.1665e+01],\n",
      "        [5.1580e+00],\n",
      "        [6.7246e+00],\n",
      "        [1.9824e+01],\n",
      "        [1.3827e+01],\n",
      "        [7.1564e+00],\n",
      "        [1.4036e+01],\n",
      "        [3.4029e+01],\n",
      "        [1.2848e+01],\n",
      "        [5.0368e+00],\n",
      "        [7.4601e+00],\n",
      "        [6.1320e+00],\n",
      "        [5.3490e+00],\n",
      "        [9.6671e+00],\n",
      "        [2.0605e+01],\n",
      "        [6.2927e+01],\n",
      "        [6.3441e+00],\n",
      "        [1.0510e+01],\n",
      "        [8.5943e+00],\n",
      "        [3.0959e+01],\n",
      "        [1.4505e+01],\n",
      "        [3.1350e+01],\n",
      "        [7.8925e+00],\n",
      "        [1.1370e+01],\n",
      "        [6.4387e+00],\n",
      "        [1.1860e+01],\n",
      "        [1.9705e+00],\n",
      "        [1.4951e+01],\n",
      "        [2.7315e+01],\n",
      "        [7.8464e+00],\n",
      "        [8.4700e+00],\n",
      "        [3.7067e+00],\n",
      "        [1.7904e+01],\n",
      "        [1.3404e+01],\n",
      "        [1.1171e+01],\n",
      "        [3.7014e-01],\n",
      "        [8.9431e-01],\n",
      "        [6.2941e+00],\n",
      "        [3.4629e+00],\n",
      "        [5.4893e+00],\n",
      "        [1.1661e+01],\n",
      "        [1.4886e+01],\n",
      "        [8.7223e+00],\n",
      "        [3.4790e+00],\n",
      "        [8.7498e+00],\n",
      "        [8.6132e+00],\n",
      "        [6.9613e+00],\n",
      "        [9.8051e+01],\n",
      "        [1.4210e+01],\n",
      "        [4.5501e+00],\n",
      "        [4.7762e+00],\n",
      "        [6.2258e-01],\n",
      "        [4.0069e+00],\n",
      "        [1.7465e+00],\n",
      "        [1.4209e+02],\n",
      "        [7.3085e+00],\n",
      "        [1.3301e+01],\n",
      "        [1.3511e+01],\n",
      "        [1.7568e-01],\n",
      "        [8.3289e+00],\n",
      "        [8.3061e+00],\n",
      "        [8.3209e+00],\n",
      "        [1.2875e+01],\n",
      "        [2.0800e+01],\n",
      "        [3.9515e+01]])\n",
      "11:29 inference.trainer    DEBUG   t_xz0: tensor([[       -inf, -1.0280e+02],\n",
      "        [       -inf, -3.4710e+02],\n",
      "        [        inf, -1.8290e+02],\n",
      "        [       -inf, -4.3101e+02],\n",
      "        [        inf, -1.5199e+03],\n",
      "        [       -inf, -1.3731e+02],\n",
      "        [       -inf, -4.6601e+02],\n",
      "        [       -inf, -2.5107e+02],\n",
      "        [       -inf, -9.8958e+02],\n",
      "        [        inf, -2.1940e+02],\n",
      "        [        inf,  1.4012e+00],\n",
      "        [        inf, -2.9385e+02],\n",
      "        [       -inf, -2.5483e+02],\n",
      "        [        inf, -4.8616e+01],\n",
      "        [        inf,  2.9041e+01],\n",
      "        [       -inf, -2.0632e+03],\n",
      "        [        inf, -6.5313e+01],\n",
      "        [       -inf, -3.3153e+02],\n",
      "        [        inf, -2.0999e+02],\n",
      "        [        inf, -2.6227e+02],\n",
      "        [       -inf, -2.1653e+02],\n",
      "        [       -inf, -3.2082e+02],\n",
      "        [        inf, -5.6871e+02],\n",
      "        [        inf, -5.8416e+02],\n",
      "        [        inf, -4.5575e+01],\n",
      "        [        inf, -3.2265e+01],\n",
      "        [       -inf, -4.7211e+02],\n",
      "        [        inf, -1.4216e+01],\n",
      "        [        inf,  8.2168e+01],\n",
      "        [       -inf, -3.3045e+02],\n",
      "        [       -inf, -2.1997e+02],\n",
      "        [        inf, -3.2048e+02],\n",
      "        [        inf, -3.4325e+02],\n",
      "        [       -inf, -2.1040e+02],\n",
      "        [        inf, -1.2362e+02],\n",
      "        [        inf,  2.7438e+01],\n",
      "        [       -inf, -5.6804e+02],\n",
      "        [       -inf, -8.0563e+01],\n",
      "        [       -inf, -1.3579e+02],\n",
      "        [        inf, -6.5730e+02],\n",
      "        [       -inf, -3.2589e+02],\n",
      "        [       -inf, -3.3725e+02],\n",
      "        [       -inf, -1.0753e+02],\n",
      "        [       -inf, -6.3021e+02],\n",
      "        [       -inf, -4.4506e+02],\n",
      "        [       -inf, -1.3098e+03],\n",
      "        [        inf,  1.3212e+01],\n",
      "        [       -inf, -6.6985e+02],\n",
      "        [        inf, -1.4429e+02],\n",
      "        [        inf, -1.5971e+01],\n",
      "        [       -inf, -1.0662e+02],\n",
      "        [       -inf, -4.9178e+02],\n",
      "        [        inf, -2.6554e+02],\n",
      "        [        inf, -6.9228e+02],\n",
      "        [        inf, -1.3664e+03],\n",
      "        [       -inf, -6.1678e+02],\n",
      "        [        inf, -5.0349e+02],\n",
      "        [        inf, -4.8837e+03],\n",
      "        [        inf, -5.9250e+02],\n",
      "        [       -inf, -1.3900e+03],\n",
      "        [       -inf, -5.1374e+02],\n",
      "        [        inf, -2.4073e+03],\n",
      "        [        inf, -2.9524e+02],\n",
      "        [       -inf, -6.9615e+02],\n",
      "        [       -inf, -2.6813e+02],\n",
      "        [        inf,  8.3704e+00],\n",
      "        [        inf, -4.0023e+02],\n",
      "        [        inf, -1.4473e+02],\n",
      "        [       -inf, -1.2296e+02],\n",
      "        [       -inf, -6.2947e+02],\n",
      "        [       -inf, -8.7409e+02],\n",
      "        [       -inf, -2.8843e+02],\n",
      "        [        inf, -1.0177e+02],\n",
      "        [       -inf, -3.9156e+02],\n",
      "        [       -inf, -1.9854e+02],\n",
      "        [       -inf, -2.9656e+02],\n",
      "        [       -inf, -7.2477e+02],\n",
      "        [       -inf, -8.2493e+02],\n",
      "        [        inf, -9.1494e+02],\n",
      "        [        inf, -1.9748e+01],\n",
      "        [       -inf, -5.2702e+02],\n",
      "        [       -inf, -3.1856e+02],\n",
      "        [        inf, -8.2145e+02],\n",
      "        [        inf, -5.4694e+01],\n",
      "        [        inf, -1.0560e+03],\n",
      "        [       -inf, -6.4394e+02],\n",
      "        [        inf, -4.8289e+02],\n",
      "        [       -inf, -2.0606e+02],\n",
      "        [       -inf, -5.1599e+02],\n",
      "        [       -inf, -6.9504e+02],\n",
      "        [       -inf, -3.6906e+02],\n",
      "        [        inf, -1.4472e+01],\n",
      "        [       -inf, -2.6904e+02],\n",
      "        [       -inf, -1.4379e+02],\n",
      "        [       -inf, -6.1159e+02],\n",
      "        [        inf, -1.3429e+02],\n",
      "        [        inf, -9.4806e+02],\n",
      "        [        inf, -7.3841e+01],\n",
      "        [       -inf, -6.1906e+02],\n",
      "        [        inf,  1.2546e+02],\n",
      "        [        inf,  4.6607e+01],\n",
      "        [        inf, -2.9172e+02],\n",
      "        [       -inf, -1.9344e+02],\n",
      "        [       -inf, -5.5037e+02],\n",
      "        [       -inf, -9.8394e+02],\n",
      "        [       -inf, -2.5430e+02],\n",
      "        [       -inf, -4.4451e+02],\n",
      "        [       -inf, -2.5625e+02],\n",
      "        [        inf, -7.9361e+01],\n",
      "        [        inf, -3.0492e+01],\n",
      "        [        inf, -8.4448e+02],\n",
      "        [       -inf, -3.3289e+02],\n",
      "        [       -inf, -6.6524e+02],\n",
      "        [       -inf, -5.5998e+02],\n",
      "        [       -inf, -8.9899e+02],\n",
      "        [       -inf, -1.9723e+02],\n",
      "        [        inf,  7.6010e+01],\n",
      "        [       -inf, -1.2721e+03],\n",
      "        [       -inf, -1.8190e+02],\n",
      "        [       -inf, -8.3508e+02],\n",
      "        [        inf, -5.3143e+01],\n",
      "        [       -inf, -9.3886e+02],\n",
      "        [        inf, -1.1765e+02],\n",
      "        [       -inf, -1.8610e+02],\n",
      "        [        inf, -1.1115e+02],\n",
      "        [       -inf, -6.8963e+02],\n",
      "        [       -inf, -8.6350e+01],\n",
      "        [       -inf, -1.2114e+03]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:29 inference.trainer    DEBUG   s_hat: tensor([[0.4913],\n",
      "        [0.5051],\n",
      "        [0.4941],\n",
      "        [0.4765],\n",
      "        [0.4417],\n",
      "        [0.4916],\n",
      "        [0.4993],\n",
      "        [0.5033],\n",
      "        [0.4882],\n",
      "        [0.4204],\n",
      "        [0.5047],\n",
      "        [0.4955],\n",
      "        [0.5052],\n",
      "        [0.4992],\n",
      "        [0.4856],\n",
      "        [0.4531],\n",
      "        [0.4666],\n",
      "        [0.5269],\n",
      "        [0.4823],\n",
      "        [0.5920],\n",
      "        [0.4980],\n",
      "        [0.4846],\n",
      "        [0.5377],\n",
      "        [0.5312],\n",
      "        [0.4798],\n",
      "        [0.5017],\n",
      "        [0.5231],\n",
      "        [0.5038],\n",
      "        [0.5370],\n",
      "        [0.5714],\n",
      "        [0.5107],\n",
      "        [0.5520],\n",
      "        [0.5678],\n",
      "        [0.4865],\n",
      "        [0.5179],\n",
      "        [0.4767],\n",
      "        [0.4727],\n",
      "        [0.4889],\n",
      "        [0.4827],\n",
      "        [0.5623],\n",
      "        [0.4423],\n",
      "        [0.5416],\n",
      "        [0.5303],\n",
      "        [0.4779],\n",
      "        [0.4787],\n",
      "        [0.5452],\n",
      "        [0.4411],\n",
      "        [0.4844],\n",
      "        [0.4444],\n",
      "        [0.5209],\n",
      "        [0.4926],\n",
      "        [0.4942],\n",
      "        [0.5166],\n",
      "        [0.4828],\n",
      "        [0.4556],\n",
      "        [0.4865],\n",
      "        [0.5248],\n",
      "        [0.5013],\n",
      "        [0.5684],\n",
      "        [0.4940],\n",
      "        [0.4942],\n",
      "        [0.5105],\n",
      "        [0.4973],\n",
      "        [0.5269],\n",
      "        [0.5264],\n",
      "        [0.5196],\n",
      "        [0.5267],\n",
      "        [0.5293],\n",
      "        [0.4988],\n",
      "        [0.5832],\n",
      "        [0.4688],\n",
      "        [0.4895],\n",
      "        [0.4678],\n",
      "        [0.4810],\n",
      "        [0.4889],\n",
      "        [0.4898],\n",
      "        [0.5293],\n",
      "        [0.4677],\n",
      "        [0.5013],\n",
      "        [0.4831],\n",
      "        [0.5285],\n",
      "        [0.5348],\n",
      "        [0.5409],\n",
      "        [0.5076],\n",
      "        [0.4457],\n",
      "        [0.4585],\n",
      "        [0.4730],\n",
      "        [0.4859],\n",
      "        [0.4572],\n",
      "        [0.4968],\n",
      "        [0.5940],\n",
      "        [0.4933],\n",
      "        [0.4850],\n",
      "        [0.5016],\n",
      "        [0.4727],\n",
      "        [0.5101],\n",
      "        [0.5368],\n",
      "        [0.5022],\n",
      "        [0.5449],\n",
      "        [0.5009],\n",
      "        [0.5021],\n",
      "        [0.5793],\n",
      "        [0.4939],\n",
      "        [0.5033],\n",
      "        [0.5341],\n",
      "        [0.4892],\n",
      "        [0.5151],\n",
      "        [0.5137],\n",
      "        [0.5227],\n",
      "        [0.5095],\n",
      "        [0.5067],\n",
      "        [0.4963],\n",
      "        [0.4884],\n",
      "        [0.4850],\n",
      "        [0.4941],\n",
      "        [0.4462],\n",
      "        [0.5701],\n",
      "        [0.4909],\n",
      "        [0.5030],\n",
      "        [0.5263],\n",
      "        [0.4491],\n",
      "        [0.5295],\n",
      "        [0.4946],\n",
      "        [0.4952],\n",
      "        [0.5523],\n",
      "        [0.5326],\n",
      "        [0.5072],\n",
      "        [0.5512]], grad_fn=<MulBackward0>)\n",
      "11:29 inference.trainer    DEBUG   log_r_hat: tensor([[ 0.0349],\n",
      "        [-0.0204],\n",
      "        [ 0.0236],\n",
      "        [ 0.0941],\n",
      "        [ 0.2344],\n",
      "        [ 0.0337],\n",
      "        [ 0.0028],\n",
      "        [-0.0134],\n",
      "        [ 0.0473],\n",
      "        [ 0.3213],\n",
      "        [-0.0190],\n",
      "        [ 0.0181],\n",
      "        [-0.0206],\n",
      "        [ 0.0033],\n",
      "        [ 0.0578],\n",
      "        [ 0.1882],\n",
      "        [ 0.1339],\n",
      "        [-0.1079],\n",
      "        [ 0.0709],\n",
      "        [-0.3721],\n",
      "        [ 0.0079],\n",
      "        [ 0.0618],\n",
      "        [-0.1511],\n",
      "        [-0.1250],\n",
      "        [ 0.0808],\n",
      "        [-0.0070],\n",
      "        [-0.0926],\n",
      "        [-0.0154],\n",
      "        [-0.1483],\n",
      "        [-0.2877],\n",
      "        [-0.0430],\n",
      "        [-0.2088],\n",
      "        [-0.2731],\n",
      "        [ 0.0541],\n",
      "        [-0.0716],\n",
      "        [ 0.0933],\n",
      "        [ 0.1095],\n",
      "        [ 0.0444],\n",
      "        [ 0.0693],\n",
      "        [-0.2506],\n",
      "        [ 0.2320],\n",
      "        [-0.1667],\n",
      "        [-0.1213],\n",
      "        [ 0.0886],\n",
      "        [ 0.0851],\n",
      "        [-0.1813],\n",
      "        [ 0.2368],\n",
      "        [ 0.0624],\n",
      "        [ 0.2234],\n",
      "        [-0.0836],\n",
      "        [ 0.0297],\n",
      "        [ 0.0230],\n",
      "        [-0.0666],\n",
      "        [ 0.0689],\n",
      "        [ 0.1781],\n",
      "        [ 0.0540],\n",
      "        [-0.0991],\n",
      "        [-0.0053],\n",
      "        [-0.2752],\n",
      "        [ 0.0241],\n",
      "        [ 0.0231],\n",
      "        [-0.0421],\n",
      "        [ 0.0110],\n",
      "        [-0.1077],\n",
      "        [-0.1057],\n",
      "        [-0.0785],\n",
      "        [-0.1071],\n",
      "        [-0.1172],\n",
      "        [ 0.0048],\n",
      "        [-0.3358],\n",
      "        [ 0.1251],\n",
      "        [ 0.0420],\n",
      "        [ 0.1289],\n",
      "        [ 0.0759],\n",
      "        [ 0.0445],\n",
      "        [ 0.0407],\n",
      "        [-0.1172],\n",
      "        [ 0.1295],\n",
      "        [-0.0052],\n",
      "        [ 0.0677],\n",
      "        [-0.1142],\n",
      "        [-0.1392],\n",
      "        [-0.1640],\n",
      "        [-0.0305],\n",
      "        [ 0.2179],\n",
      "        [ 0.1664],\n",
      "        [ 0.1080],\n",
      "        [ 0.0562],\n",
      "        [ 0.1718],\n",
      "        [ 0.0128],\n",
      "        [-0.3806],\n",
      "        [ 0.0269],\n",
      "        [ 0.0602],\n",
      "        [-0.0062],\n",
      "        [ 0.1094],\n",
      "        [-0.0404],\n",
      "        [-0.1473],\n",
      "        [-0.0086],\n",
      "        [-0.1803],\n",
      "        [-0.0034],\n",
      "        [-0.0083],\n",
      "        [-0.3200],\n",
      "        [ 0.0245],\n",
      "        [-0.0132],\n",
      "        [-0.1366],\n",
      "        [ 0.0433],\n",
      "        [-0.0604],\n",
      "        [-0.0547],\n",
      "        [-0.0907],\n",
      "        [-0.0379],\n",
      "        [-0.0267],\n",
      "        [ 0.0147],\n",
      "        [ 0.0463],\n",
      "        [ 0.0600],\n",
      "        [ 0.0237],\n",
      "        [ 0.2162],\n",
      "        [-0.2822],\n",
      "        [ 0.0363],\n",
      "        [-0.0121],\n",
      "        [-0.1055],\n",
      "        [ 0.2043],\n",
      "        [-0.1181],\n",
      "        [ 0.0216],\n",
      "        [ 0.0191],\n",
      "        [-0.2101],\n",
      "        [-0.1305],\n",
      "        [-0.0287],\n",
      "        [-0.2053]], grad_fn=<AddmmBackward>)\n",
      "11:29 inference.trainer    DEBUG   t_hat0: tensor([[ 1.2592e-02, -1.0169e-01],\n",
      "        [-7.9803e-02, -7.7921e-02],\n",
      "        [ 3.9979e-02,  9.4773e-02],\n",
      "        [-4.6056e-02, -5.8485e-03],\n",
      "        [ 5.4186e-02, -6.6474e-03],\n",
      "        [-4.0846e-02, -9.5656e-02],\n",
      "        [ 4.6928e-02,  2.0847e-02],\n",
      "        [ 3.5585e-04,  3.1233e-02],\n",
      "        [ 4.4648e-02,  3.1985e-02],\n",
      "        [ 5.1798e-02,  7.0559e-02],\n",
      "        [-9.7368e-02, -7.3123e-02],\n",
      "        [ 7.2322e-02, -1.5862e-03],\n",
      "        [-4.9897e-02, -7.5272e-02],\n",
      "        [-2.0711e-02, -4.4565e-03],\n",
      "        [-1.7785e-02, -4.0699e-02],\n",
      "        [ 6.6319e-02,  9.1502e-02],\n",
      "        [ 8.8598e-03, -1.8673e-02],\n",
      "        [ 3.1880e-02, -3.6991e-02],\n",
      "        [ 3.0840e-02,  2.4749e-02],\n",
      "        [-1.4498e-02, -7.1383e-02],\n",
      "        [-3.9345e-02, -1.5065e-01],\n",
      "        [-1.7122e-04, -2.5255e-02],\n",
      "        [ 3.1075e-02, -4.5471e-02],\n",
      "        [ 3.6819e-02,  3.4215e-02],\n",
      "        [-4.5327e-02, -1.3883e-02],\n",
      "        [-7.4999e-02, -8.1378e-02],\n",
      "        [-3.9847e-02,  3.1876e-02],\n",
      "        [-2.7730e-02, -8.3994e-02],\n",
      "        [-7.3002e-02,  3.6210e-02],\n",
      "        [ 1.3239e-02,  4.0141e-04],\n",
      "        [ 6.0072e-02,  2.5575e-02],\n",
      "        [ 6.4130e-02,  1.6796e-01],\n",
      "        [ 4.0884e-02,  1.2168e-01],\n",
      "        [-9.4295e-02, -3.5583e-02],\n",
      "        [ 4.5115e-02,  3.7218e-02],\n",
      "        [-5.7596e-02, -8.7781e-02],\n",
      "        [ 4.7304e-02,  8.3121e-02],\n",
      "        [ 2.4073e-02,  4.9154e-03],\n",
      "        [-4.9727e-02,  1.7833e-02],\n",
      "        [ 9.5013e-03,  1.0090e-02],\n",
      "        [-5.9624e-02, -2.7887e-02],\n",
      "        [-5.2934e-03,  7.4800e-04],\n",
      "        [-7.4315e-02, -5.1306e-02],\n",
      "        [ 5.8022e-02,  3.0582e-03],\n",
      "        [-8.1669e-02, -8.0034e-02],\n",
      "        [ 3.6852e-02, -1.1059e-02],\n",
      "        [ 5.3334e-02,  1.0627e-01],\n",
      "        [ 5.9777e-02, -1.4618e-02],\n",
      "        [ 1.6091e-02,  6.6444e-02],\n",
      "        [-3.0568e-02, -1.4800e-01],\n",
      "        [-4.3360e-02, -2.3365e-02],\n",
      "        [ 7.0204e-02,  1.9252e-02],\n",
      "        [ 8.5400e-02,  5.4180e-02],\n",
      "        [ 2.2236e-02,  1.1122e-02],\n",
      "        [-3.3022e-02, -2.0510e-01],\n",
      "        [ 5.3569e-02,  1.3483e-01],\n",
      "        [ 2.7173e-02,  2.2312e-02],\n",
      "        [ 9.7475e-02, -3.2292e-02],\n",
      "        [ 2.5985e-02, -4.7165e-02],\n",
      "        [ 5.9798e-02, -3.1983e-02],\n",
      "        [ 6.4873e-02,  6.0516e-03],\n",
      "        [-7.1076e-02, -8.1198e-02],\n",
      "        [ 5.4631e-02, -2.7138e-02],\n",
      "        [ 8.4392e-02,  3.1195e-04],\n",
      "        [-6.5602e-02, -4.7124e-02],\n",
      "        [-6.9897e-02, -5.5294e-02],\n",
      "        [ 9.0931e-02,  4.2900e-02],\n",
      "        [ 5.2728e-02,  2.7904e-03],\n",
      "        [-4.6272e-02, -6.1257e-02],\n",
      "        [ 4.7891e-02, -3.6394e-02],\n",
      "        [-3.4038e-02, -9.4637e-02],\n",
      "        [-2.9990e-02, -4.7029e-02],\n",
      "        [ 4.0649e-02, -1.3460e-02],\n",
      "        [ 5.5245e-02,  9.4922e-03],\n",
      "        [-8.0176e-02, -4.8228e-02],\n",
      "        [ 1.3442e-02, -3.6619e-02],\n",
      "        [-4.4086e-02, -7.9331e-02],\n",
      "        [ 4.5505e-02, -5.6126e-02],\n",
      "        [ 1.0628e-01, -1.8078e-03],\n",
      "        [-3.6030e-02, -7.5730e-03],\n",
      "        [ 3.4116e-02, -8.2290e-02],\n",
      "        [ 1.3934e-03,  9.5171e-02],\n",
      "        [ 6.9029e-02, -9.3352e-02],\n",
      "        [-5.1604e-02, -5.8741e-02],\n",
      "        [ 5.6617e-02, -7.4112e-02],\n",
      "        [-7.2525e-02, -6.1791e-02],\n",
      "        [ 7.2513e-02, -2.1153e-02],\n",
      "        [-6.6665e-02, -3.1192e-02],\n",
      "        [ 7.0862e-03,  4.3514e-02],\n",
      "        [ 8.2417e-02,  2.3617e-02],\n",
      "        [ 1.8793e-02,  5.8884e-02],\n",
      "        [ 2.6893e-02, -5.3663e-02],\n",
      "        [-5.2974e-02, -1.4776e-02],\n",
      "        [-2.9949e-02, -3.7226e-02],\n",
      "        [ 4.4136e-02,  5.0087e-02],\n",
      "        [-2.0650e-03, -4.0567e-03],\n",
      "        [ 4.1610e-03, -1.2628e-01],\n",
      "        [-6.5861e-02, -5.7499e-02],\n",
      "        [-6.8096e-05,  4.3185e-03],\n",
      "        [-9.3815e-02, -2.6012e-02],\n",
      "        [-8.4059e-02, -1.2656e-01],\n",
      "        [ 7.2680e-02,  7.7609e-02],\n",
      "        [ 1.1916e-02, -3.5843e-04],\n",
      "        [ 1.7757e-02,  3.4993e-02],\n",
      "        [ 1.0122e-01, -6.2433e-02],\n",
      "        [-4.6678e-02, -1.2723e-02],\n",
      "        [-3.4955e-02, -2.3789e-02],\n",
      "        [-5.7188e-02,  3.6483e-03],\n",
      "        [ 2.8815e-02,  8.8666e-02],\n",
      "        [-5.4177e-02, -8.9313e-02],\n",
      "        [-1.5081e-02, -2.3947e-02],\n",
      "        [ 3.4738e-02,  3.9023e-02],\n",
      "        [ 4.6543e-02, -6.4650e-02],\n",
      "        [-6.7126e-02,  1.2075e-02],\n",
      "        [ 5.1695e-02,  3.1898e-02],\n",
      "        [-6.3416e-02, -5.1709e-02],\n",
      "        [-1.0060e-01, -2.4198e-02],\n",
      "        [ 5.5038e-02,  5.5271e-02],\n",
      "        [-6.1340e-02, -5.0203e-02],\n",
      "        [ 8.4292e-02, -9.2559e-02],\n",
      "        [-7.7115e-02,  2.0755e-02],\n",
      "        [ 1.8499e-02, -4.9776e-02],\n",
      "        [-4.4229e-02, -3.1837e-02],\n",
      "        [-3.7945e-02, -6.9424e-02],\n",
      "        [ 9.2646e-03, -1.4824e-01],\n",
      "        [ 3.1424e-02, -2.9239e-02],\n",
      "        [-3.4000e-02, -3.5295e-02],\n",
      "        [-5.2585e-02, -1.2137e-01]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:29 inference.trainer    DEBUG   x_gradient: None\n",
      "11:29 inference.trainer    DEBUG   theta0: tensor([[ 0.0000, -1.9024],\n",
      "        [ 0.0000, -1.8513],\n",
      "        [ 0.0000, -1.9221],\n",
      "        [ 0.0000, -1.8915],\n",
      "        [ 0.0000, -1.9754],\n",
      "        [ 0.0000, -1.8421],\n",
      "        [ 0.0000, -1.8977],\n",
      "        [ 0.0000, -1.8818],\n",
      "        [ 0.0000, -1.8853],\n",
      "        [ 0.0000, -1.8868],\n",
      "        [ 0.0000, -1.8887],\n",
      "        [ 0.0000, -1.8825],\n",
      "        [ 0.0000, -1.9808],\n",
      "        [ 0.0000, -1.8433],\n",
      "        [ 0.0000, -1.9148],\n",
      "        [ 0.0000, -1.9659],\n",
      "        [ 0.0000, -1.8998],\n",
      "        [ 0.0000, -1.8553],\n",
      "        [ 0.0000, -1.9215],\n",
      "        [ 0.0000, -1.9047],\n",
      "        [ 0.0000, -1.9652],\n",
      "        [ 0.0000, -1.8836],\n",
      "        [ 0.0000, -1.8507],\n",
      "        [ 0.0000, -1.9354],\n",
      "        [ 0.0000, -1.8716],\n",
      "        [ 0.0000, -1.8863],\n",
      "        [ 0.0000, -1.9887],\n",
      "        [ 0.0000, -1.9456],\n",
      "        [ 0.0000, -1.8916],\n",
      "        [ 0.0000, -1.9248],\n",
      "        [ 0.0000, -1.8661],\n",
      "        [ 0.0000, -1.8795],\n",
      "        [ 0.0000, -1.9405],\n",
      "        [ 0.0000, -1.9162],\n",
      "        [ 0.0000, -1.9330],\n",
      "        [ 0.0000, -1.9182],\n",
      "        [ 0.0000, -1.8675],\n",
      "        [ 0.0000, -1.8773],\n",
      "        [ 0.0000, -1.8842],\n",
      "        [ 0.0000, -1.8909],\n",
      "        [ 0.0000, -1.7688],\n",
      "        [ 0.0000, -1.8967],\n",
      "        [ 0.0000, -1.8755],\n",
      "        [ 0.0000, -1.8474],\n",
      "        [ 0.0000, -1.9162],\n",
      "        [ 0.0000, -1.8373],\n",
      "        [ 0.0000, -1.7851],\n",
      "        [ 0.0000, -1.8988],\n",
      "        [ 0.0000, -1.8658],\n",
      "        [ 0.0000, -1.9346],\n",
      "        [ 0.0000, -1.9041],\n",
      "        [ 0.0000, -1.8945],\n",
      "        [ 0.0000, -1.9090],\n",
      "        [ 0.0000, -1.9036],\n",
      "        [ 0.0000, -1.8984],\n",
      "        [ 0.0000, -1.8259],\n",
      "        [ 0.0000, -1.9683],\n",
      "        [ 0.0000, -1.8835],\n",
      "        [ 0.0000, -1.9274],\n",
      "        [ 0.0000, -1.9007],\n",
      "        [ 0.0000, -1.9984],\n",
      "        [ 0.0000, -1.9234],\n",
      "        [ 0.0000, -1.8237],\n",
      "        [ 0.0000, -1.8817],\n",
      "        [ 0.0000, -1.8890],\n",
      "        [ 0.0000, -1.7816],\n",
      "        [ 0.0000, -1.8760],\n",
      "        [ 0.0000, -1.9100],\n",
      "        [ 0.0000, -1.9666],\n",
      "        [ 0.0000, -1.8577],\n",
      "        [ 0.0000, -1.9087],\n",
      "        [ 0.0000, -1.9134],\n",
      "        [ 0.0000, -1.9331],\n",
      "        [ 0.0000, -1.8048],\n",
      "        [ 0.0000, -1.9073],\n",
      "        [ 0.0000, -1.8014],\n",
      "        [ 0.0000, -1.9546],\n",
      "        [ 0.0000, -1.8280],\n",
      "        [ 0.0000, -1.9219],\n",
      "        [ 0.0000, -1.9427],\n",
      "        [ 0.0000, -2.0177],\n",
      "        [ 0.0000, -1.8467],\n",
      "        [ 0.0000, -1.8716],\n",
      "        [ 0.0000, -2.0114],\n",
      "        [ 0.0000, -1.9567],\n",
      "        [ 0.0000, -1.8880],\n",
      "        [ 0.0000, -1.8892],\n",
      "        [ 0.0000, -1.8789],\n",
      "        [ 0.0000, -1.9506],\n",
      "        [ 0.0000, -1.9617],\n",
      "        [ 0.0000, -1.8523],\n",
      "        [ 0.0000, -1.9932],\n",
      "        [ 0.0000, -1.7659],\n",
      "        [ 0.0000, -1.9458],\n",
      "        [ 0.0000, -1.8286],\n",
      "        [ 0.0000, -1.9623],\n",
      "        [ 0.0000, -1.8793],\n",
      "        [ 0.0000, -1.9257],\n",
      "        [ 0.0000, -1.8618],\n",
      "        [ 0.0000, -1.9943],\n",
      "        [ 0.0000, -1.8949],\n",
      "        [ 0.0000, -1.8909],\n",
      "        [ 0.0000, -1.8606],\n",
      "        [ 0.0000, -1.9542],\n",
      "        [ 0.0000, -1.8284],\n",
      "        [ 0.0000, -1.9062],\n",
      "        [ 0.0000, -1.9528],\n",
      "        [ 0.0000, -1.9476],\n",
      "        [ 0.0000, -1.7816],\n",
      "        [ 0.0000, -1.8686],\n",
      "        [ 0.0000, -1.8254],\n",
      "        [ 0.0000, -1.8471],\n",
      "        [ 0.0000, -1.9050],\n",
      "        [ 0.0000, -1.9499],\n",
      "        [ 0.0000, -1.9740],\n",
      "        [ 0.0000, -2.0263],\n",
      "        [ 0.0000, -1.7896],\n",
      "        [ 0.0000, -1.9144],\n",
      "        [ 0.0000, -1.8427],\n",
      "        [ 0.0000, -1.9201],\n",
      "        [ 0.0000, -1.8398],\n",
      "        [ 0.0000, -1.8715],\n",
      "        [ 0.0000, -1.9490],\n",
      "        [ 0.0000, -1.9026],\n",
      "        [ 0.0000, -1.8608],\n",
      "        [ 0.0000, -1.8698],\n",
      "        [ 0.0000, -1.8860],\n",
      "        [ 0.0000, -1.9577]], grad_fn=<CopyBackwards>)\n",
      "11:29 inference.trainer    DEBUG   x: tensor([[[0.1808, 0.1976, 0.1892,  ..., 0.2012, 0.1880, 0.1832],\n",
      "         [0.1712, 0.1880, 0.1928,  ..., 0.1820, 0.1653, 0.2012],\n",
      "         [0.2155, 0.1760, 0.1856,  ..., 0.1856, 0.1772, 0.1964],\n",
      "         ...,\n",
      "         [0.1832, 0.1808, 0.2155,  ..., 0.2203, 0.1796, 0.1688],\n",
      "         [0.1988, 0.1784, 0.1868,  ..., 0.1976, 0.2024, 0.1664],\n",
      "         [0.1964, 0.2036, 0.2024,  ..., 0.1796, 0.1880, 0.1844]],\n",
      "\n",
      "        [[0.2060, 0.1653, 0.2143,  ..., 0.1976, 0.1988, 0.2036],\n",
      "         [0.1904, 0.1988, 0.1664,  ..., 0.2143, 0.1736, 0.1988],\n",
      "         [0.1964, 0.1772, 0.1928,  ..., 0.1832, 0.1856, 0.1964],\n",
      "         ...,\n",
      "         [0.1868, 0.1892, 0.1856,  ..., 0.2060, 0.2012, 0.1856],\n",
      "         [0.1988, 0.1676, 0.1988,  ..., 0.1736, 0.2000, 0.1724],\n",
      "         [0.1940, 0.2012, 0.1772,  ..., 0.2012, 0.2000, 0.1892]],\n",
      "\n",
      "        [[0.1820, 0.2024, 0.2179,  ..., 0.1892, 0.1712, 0.1880],\n",
      "         [0.1617, 0.2060, 0.1808,  ..., 0.1880, 0.1892, 0.1760],\n",
      "         [0.2155, 0.1916, 0.2084,  ..., 0.1844, 0.1688, 0.1892],\n",
      "         ...,\n",
      "         [0.1760, 0.1916, 0.1856,  ..., 0.2012, 0.1712, 0.1653],\n",
      "         [0.1641, 0.2155, 0.2287,  ..., 0.1988, 0.2048, 0.1808],\n",
      "         [0.1988, 0.2167, 0.1509,  ..., 0.1916, 0.1928, 0.1988]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1820, 0.1772, 0.1928,  ..., 0.1760, 0.1952, 0.2143],\n",
      "         [0.1653, 0.1688, 0.1844,  ..., 0.1976, 0.1557, 0.1928],\n",
      "         [0.1868, 0.2024, 0.2084,  ..., 0.1964, 0.1772, 0.1772],\n",
      "         ...,\n",
      "         [0.1868, 0.2060, 0.1880,  ..., 0.1748, 0.1688, 0.1724],\n",
      "         [0.1808, 0.2060, 0.1880,  ..., 0.1952, 0.2155, 0.2143],\n",
      "         [0.2108, 0.1868, 0.2024,  ..., 0.2371, 0.2000, 0.1736]],\n",
      "\n",
      "        [[0.1940, 0.1832, 0.1880,  ..., 0.1724, 0.1736, 0.1940],\n",
      "         [0.1832, 0.2060, 0.1796,  ..., 0.1784, 0.1832, 0.1928],\n",
      "         [0.1784, 0.1820, 0.1904,  ..., 0.1940, 0.1904, 0.2000],\n",
      "         ...,\n",
      "         [0.2024, 0.2000, 0.2096,  ..., 0.1940, 0.2167, 0.2024],\n",
      "         [0.2167, 0.1796, 0.1820,  ..., 0.1856, 0.1928, 0.1916],\n",
      "         [0.1533, 0.1904, 0.2179,  ..., 0.2048, 0.1748, 0.1952]],\n",
      "\n",
      "        [[0.2036, 0.2179, 0.1928,  ..., 0.1904, 0.1928, 0.1748],\n",
      "         [0.1796, 0.1940, 0.1712,  ..., 0.2024, 0.1880, 0.1760],\n",
      "         [0.1904, 0.2024, 0.1856,  ..., 0.2072, 0.1916, 0.1904],\n",
      "         ...,\n",
      "         [0.1712, 0.1964, 0.2036,  ..., 0.2072, 0.2060, 0.2167],\n",
      "         [0.1880, 0.1676, 0.1904,  ..., 0.1748, 0.1748, 0.1820],\n",
      "         [0.2311, 0.1736, 0.1676,  ..., 0.1916, 0.1976, 0.1916]]])\n",
      "11:29 inference.trainer    DEBUG   y: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "11:29 inference.trainer    DEBUG   r_xz: tensor([[8.0149e+00],\n",
      "        [1.3708e+00],\n",
      "        [8.8406e+00],\n",
      "        [8.2655e+00],\n",
      "        [1.3389e+01],\n",
      "        [2.5328e+01],\n",
      "        [7.9323e+00],\n",
      "        [1.6319e+01],\n",
      "        [7.0769e+00],\n",
      "        [1.0407e+01],\n",
      "        [6.8600e+00],\n",
      "        [8.4379e+00],\n",
      "        [1.2365e+01],\n",
      "        [1.2600e+01],\n",
      "        [1.0076e+01],\n",
      "        [4.4166e+00],\n",
      "        [7.3565e+00],\n",
      "        [1.6558e+01],\n",
      "        [8.4087e+00],\n",
      "        [7.4853e-01],\n",
      "        [1.9668e+01],\n",
      "        [1.1403e+01],\n",
      "        [1.8733e+01],\n",
      "        [1.2053e+01],\n",
      "        [1.6540e+01],\n",
      "        [6.1473e+00],\n",
      "        [1.6151e+01],\n",
      "        [8.0369e+00],\n",
      "        [6.6219e+00],\n",
      "        [4.8695e+00],\n",
      "        [5.2305e+00],\n",
      "        [1.5264e+01],\n",
      "        [9.1022e+00],\n",
      "        [5.8532e+00],\n",
      "        [2.7950e+00],\n",
      "        [6.5128e+00],\n",
      "        [2.5732e+01],\n",
      "        [1.2704e+01],\n",
      "        [8.9456e+00],\n",
      "        [6.7272e+00],\n",
      "        [6.1913e+02],\n",
      "        [1.0101e+01],\n",
      "        [4.5562e+00],\n",
      "        [7.0034e+00],\n",
      "        [6.2453e+00],\n",
      "        [1.5095e+01],\n",
      "        [4.5748e+11],\n",
      "        [7.2587e+00],\n",
      "        [1.2445e+01],\n",
      "        [7.3091e+00],\n",
      "        [1.2969e+01],\n",
      "        [2.7012e-01],\n",
      "        [8.5258e+00],\n",
      "        [8.2776e+00],\n",
      "        [3.0421e+00],\n",
      "        [4.3929e+01],\n",
      "        [1.2737e+01],\n",
      "        [6.8893e+00],\n",
      "        [7.5865e+00],\n",
      "        [6.8999e+00],\n",
      "        [1.0520e+01],\n",
      "        [4.5316e+00],\n",
      "        [5.3376e+00],\n",
      "        [1.9363e+01],\n",
      "        [6.8099e+00],\n",
      "        [1.1487e+03],\n",
      "        [5.7396e+00],\n",
      "        [1.0441e+01],\n",
      "        [1.3179e+01],\n",
      "        [5.7919e+00],\n",
      "        [8.3888e+00],\n",
      "        [9.9822e+00],\n",
      "        [2.4589e+00],\n",
      "        [4.0980e+01],\n",
      "        [1.0603e+01],\n",
      "        [1.4651e+02],\n",
      "        [1.1022e+01],\n",
      "        [4.0607e+01],\n",
      "        [6.6013e+00],\n",
      "        [3.1365e+00],\n",
      "        [2.8707e+01],\n",
      "        [7.4185e+00],\n",
      "        [2.6594e+01],\n",
      "        [1.3561e+01],\n",
      "        [1.1763e+01],\n",
      "        [8.5324e+00],\n",
      "        [3.4483e+00],\n",
      "        [1.0010e+01],\n",
      "        [4.2550e+00],\n",
      "        [7.1191e+00],\n",
      "        [1.4879e+01],\n",
      "        [1.7738e+01],\n",
      "        [2.1005e+07],\n",
      "        [6.2412e+00],\n",
      "        [5.0972e+01],\n",
      "        [9.1582e+00],\n",
      "        [1.9341e+00],\n",
      "        [3.4078e-01],\n",
      "        [1.2672e+01],\n",
      "        [2.9761e+01],\n",
      "        [3.8947e-01],\n",
      "        [1.1733e+01],\n",
      "        [2.6789e+01],\n",
      "        [6.9440e+00],\n",
      "        [8.2025e+00],\n",
      "        [5.0532e+00],\n",
      "        [3.1984e+00],\n",
      "        [2.0903e+00],\n",
      "        [1.0703e+02],\n",
      "        [4.5962e+00],\n",
      "        [1.1121e+02],\n",
      "        [1.5429e+01],\n",
      "        [4.3917e+00],\n",
      "        [1.4993e+01],\n",
      "        [2.6674e+01],\n",
      "        [6.6238e+02],\n",
      "        [3.3629e+02],\n",
      "        [6.6086e+00],\n",
      "        [1.8763e+01],\n",
      "        [8.0516e+00],\n",
      "        [4.4707e+01],\n",
      "        [1.4456e+01],\n",
      "        [1.3597e+01],\n",
      "        [8.9670e+00],\n",
      "        [2.2547e+01],\n",
      "        [9.8335e+00],\n",
      "        [7.8023e+00],\n",
      "        [8.1424e+00]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:29 inference.trainer    DEBUG   t_xz0: tensor([[       -inf, -3.0339e+02],\n",
      "        [        inf, -2.0443e+01],\n",
      "        [        inf, -1.4327e+02],\n",
      "        [       -inf, -3.8613e+02],\n",
      "        [        inf,  4.8003e+00],\n",
      "        [       -inf, -8.6615e+02],\n",
      "        [        inf, -2.3666e+02],\n",
      "        [       -inf, -3.8901e+02],\n",
      "        [        inf, -3.0935e+02],\n",
      "        [       -inf, -3.8323e+02],\n",
      "        [       -inf, -5.2331e+02],\n",
      "        [        inf, -3.4408e+02],\n",
      "        [        inf, -5.2410e-01],\n",
      "        [       -inf, -1.1439e+03],\n",
      "        [        inf, -1.6520e+02],\n",
      "        [       -inf, -1.6622e+02],\n",
      "        [       -inf, -2.7611e+02],\n",
      "        [        inf, -2.4791e+02],\n",
      "        [        inf, -1.9393e+02],\n",
      "        [       -inf, -6.7548e+02],\n",
      "        [       -inf, -1.6770e+02],\n",
      "        [       -inf, -5.0323e+02],\n",
      "        [        inf, -3.4804e+02],\n",
      "        [       -inf, -2.2242e+02],\n",
      "        [        inf, -3.2963e+02],\n",
      "        [       -inf, -4.1496e+02],\n",
      "        [        inf, -4.9154e+01],\n",
      "        [       -inf, -9.8415e+01],\n",
      "        [        inf, -1.0659e+02],\n",
      "        [       -inf, -2.4211e+02],\n",
      "        [       -inf, -6.6065e+02],\n",
      "        [       -inf, -4.7568e+02],\n",
      "        [        inf, -1.0494e+02],\n",
      "        [       -inf, -3.5588e+02],\n",
      "        [       -inf, -3.7251e+02],\n",
      "        [       -inf, -2.4695e+02],\n",
      "        [       -inf, -6.3476e+02],\n",
      "        [       -inf, -4.5423e+02],\n",
      "        [       -inf, -5.6071e+02],\n",
      "        [        inf, -1.9780e+02],\n",
      "        [        inf, -2.7865e+03],\n",
      "        [       -inf, -3.0144e+02],\n",
      "        [       -inf, -6.4653e+02],\n",
      "        [        inf, -4.4849e+02],\n",
      "        [        inf, -1.0864e+02],\n",
      "        [       -inf, -1.0508e+03],\n",
      "        [        inf, -1.9034e+03],\n",
      "        [        inf, -1.2300e+02],\n",
      "        [        inf, -5.3410e+02],\n",
      "        [        inf, -6.6931e+01],\n",
      "        [       -inf, -3.0838e+02],\n",
      "        [       -inf, -8.5067e+02],\n",
      "        [       -inf, -3.3066e+02],\n",
      "        [        inf, -1.3690e+02],\n",
      "        [        inf, -1.6301e+00],\n",
      "        [        inf, -6.7983e+02],\n",
      "        [        inf, -4.7706e+01],\n",
      "        [        inf, -3.3090e+02],\n",
      "        [        inf, -1.0042e+02],\n",
      "        [       -inf, -3.5672e+02],\n",
      "        [        inf,  6.4570e+00],\n",
      "        [        inf,  2.2222e+01],\n",
      "        [       -inf, -1.6561e+03],\n",
      "        [       -inf, -4.1448e+02],\n",
      "        [        inf, -1.0571e+02],\n",
      "        [        inf, -1.9360e+03],\n",
      "        [       -inf, -5.8307e+02],\n",
      "        [       -inf, -2.1552e+02],\n",
      "        [        inf, -4.5134e+01],\n",
      "        [        inf, -2.8725e+02],\n",
      "        [        inf, -1.2257e+02],\n",
      "        [       -inf, -2.2868e+02],\n",
      "        [       -inf, -2.6443e+02],\n",
      "        [        inf, -1.4107e+03],\n",
      "        [       -inf, -3.8702e+02],\n",
      "        [       -inf, -1.6459e+03],\n",
      "        [        inf, -3.8654e+01],\n",
      "        [       -inf, -1.0847e+03],\n",
      "        [        inf, -7.4596e+01],\n",
      "        [        inf, -8.6323e-01],\n",
      "        [        inf, -2.8462e+01],\n",
      "        [        inf, -2.8998e+02],\n",
      "        [        inf, -3.2346e+02],\n",
      "        [        inf,  4.3507e+01],\n",
      "        [       -inf, -1.9035e+02],\n",
      "        [       -inf, -5.6408e+02],\n",
      "        [       -inf, -5.4142e+02],\n",
      "        [        inf, -2.3476e+02],\n",
      "        [       -inf, -2.4977e+02],\n",
      "        [       -inf, -1.2053e+02],\n",
      "        [        inf, -5.3452e+02],\n",
      "        [       -inf, -9.4568e+01],\n",
      "        [       -inf, -3.1150e+03],\n",
      "        [        inf, -7.7593e+01],\n",
      "        [        inf, -1.1028e+03],\n",
      "        [       -inf, -9.7221e+01],\n",
      "        [        inf, -1.7934e+00],\n",
      "        [        inf,  1.7683e+02],\n",
      "        [        inf, -4.3676e+02],\n",
      "        [       -inf, -7.2529e+01],\n",
      "        [        inf,  1.1762e+02],\n",
      "        [       -inf, -3.5228e+02],\n",
      "        [       -inf, -6.3297e+02],\n",
      "        [        inf, -5.0701e+01],\n",
      "        [        inf, -3.5048e+02],\n",
      "        [       -inf, -4.2347e+02],\n",
      "        [       -inf, -2.5746e+02],\n",
      "        [        inf,  9.7669e+01],\n",
      "        [       -inf, -3.3972e+03],\n",
      "        [       -inf, -7.9787e+02],\n",
      "        [       -inf, -1.1424e+03],\n",
      "        [       -inf, -8.0581e+02],\n",
      "        [       -inf, -4.4801e+02],\n",
      "        [        inf, -9.6730e+01],\n",
      "        [       -inf, -1.0385e+02],\n",
      "        [       -inf, -9.9209e+01],\n",
      "        [        inf, -2.0200e+03],\n",
      "        [       -inf, -2.7003e+02],\n",
      "        [        inf, -7.0984e+02],\n",
      "        [       -inf, -2.2869e+02],\n",
      "        [        inf, -6.4017e+02],\n",
      "        [        inf, -3.0823e+02],\n",
      "        [       -inf, -1.4600e+02],\n",
      "        [        inf, -1.8335e+02],\n",
      "        [        inf, -4.8006e+02],\n",
      "        [       -inf, -4.9599e+02],\n",
      "        [       -inf, -4.1899e+02],\n",
      "        [       -inf, -1.4022e+02]])\n",
      "11:29 inference.trainer    DEBUG   s_hat: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "11:29 inference.trainer    DEBUG   log_r_hat: tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:29 inference.trainer    DEBUG   t_hat0: tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], grad_fn=<AddBackward0>)\n",
      "11:29 inference.trainer    DEBUG   x_gradient: None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `x >= 0. && x <= 1.' failed. input value should be between 0~1, but got nan at /Users/soumith/mc3build/conda-bld/pytorch_1549593514549/work/aten/src/THNN/generic/BCECriterion.c:60",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ccfe953cb814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mt_xz0_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../data/t_xz.npy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mn_conv_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mn_dense_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m~/work/projects/other/strong_lensing/StrongLensing-Inference/inference/inference.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, method, x_filename, y_filename, theta0_filename, r_xz_filename, t_xz0_filename, n_conv_layers, n_dense_layers, n_feature_maps, kernel_size, pooling_size, n_hidden_dense, activation, alpha, trainer, n_epochs, batch_size, initial_lr, final_lr, nesterov_momentum, validation_split, early_stopping, rescale_images, shuffle_labels, grad_x_regularization, limit_samplesize, return_first_loss, verbose)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"all\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"some\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mgrad_x_regularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_x_regularization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mreturn_first_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_first_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         )\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/projects/other/strong_lensing/StrongLensing-Inference/inference/trainer.py\u001b[0m in \u001b[0;36mtrain_ratio_model\u001b[0;34m(model, loss_functions, theta0s, xs, ys, r_xzs, t_xz0s, loss_weights, loss_labels, calculate_model_score, batch_size, trainer, initial_learning_rate, final_learning_rate, nesterov_momentum, n_epochs, clip_gradient, run_on_gpu, double_precision, validation_split, early_stopping, early_stopping_patience, grad_x_regularization, learning_curve_folder, learning_curve_filename, return_first_loss, verbose)\u001b[0m\n\u001b[1;32m    241\u001b[0m             losses = [\n\u001b[1;32m    242\u001b[0m                 \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_r_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_hat0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_xz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_xz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             ]\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgrad_x_regularization\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/projects/other/strong_lensing/StrongLensing-Inference/inference/trainer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    241\u001b[0m             losses = [\n\u001b[1;32m    242\u001b[0m                 \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_r_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_hat0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_xz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_xz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             ]\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgrad_x_regularization\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/projects/other/strong_lensing/StrongLensing-Inference/inference/losses.py\u001b[0m in \u001b[0;36maugmented_cross_entropy\u001b[0;34m(s_hat, log_r_hat, t0_hat, y_true, r_true, t0_true)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0ms_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mr_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/lensing/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lensing/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lensing/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2027\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `x >= 0. && x <= 1.' failed. input value should be between 0~1, but got nan at /Users/soumith/mc3build/conda-bld/pytorch_1549593514549/work/aten/src/THNN/generic/BCECriterion.c:60"
     ]
    }
   ],
   "source": [
    "re.train(\n",
    "    method=\"alices\",\n",
    "    x_filename=\"../data/x.npy\",\n",
    "    y_filename=\"../data/y.npy\",\n",
    "    theta0_filename=\"../data/theta.npy\",\n",
    "    r_xz_filename=\"../data/r_xz.npy\",\n",
    "    t_xz0_filename=\"../data/t_xz.npy\",\n",
    "    n_conv_layers=2,\n",
    "    n_dense_layers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "52 //2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "26 //2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5 - 1) //2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lensing)",
   "language": "python",
   "name": "lensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
